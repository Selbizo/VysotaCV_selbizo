#pragma once
//Алгоритм стабилизации видео на основе вычисление Lucas-Kanade Optical Flow
//

#include "opencv2/video/tracking.hpp"
#include <cmath>
#include <fstream>
#include <iostream>
#include <mutex>
#include <opencv2/calib3d.hpp>
#include <opencv2/core.hpp>
#include <opencv2/core/cuda.hpp>
#include <opencv2/cudaarithm.hpp>
#include <opencv2/cudafeatures2d.hpp>
#include <opencv2/cudafilters.hpp>
#include <opencv2/cudaimgproc.hpp>
#include <opencv2/cudaoptflow.hpp> 
#include <opencv2/cudawarping.hpp>
#include <opencv2/dnn.hpp>
#include <opencv2/highgui.hpp>
#include <opencv2/imgproc.hpp>
#include <opencv2/opencv.hpp>
#include <opencv2/videoio.hpp>
#include <stdio.h>
#include <thread>
#include <vector>

using namespace cv;
using namespace std;


Mat videoStabHomograpy(cuda::GpuMat& gFrame, vector<Point2f>& p0, vector<Point2f>& p1, vector<Mat>& homoTransforms)
{
	// Вычисляем гомографию
	Mat H;
	if (p0.size() >= 4) {
		H = findHomography(p0, p1, RANSAC);
		homoTransforms.push_back(H);
	}
	else {
		homoTransforms.push_back(Mat::eye(3, 3, CV_64F));
	}

	if (homoTransforms.size() < 400) {
		return homoTransforms.back();
	}
	// Вычисляем среднее преобразование в окне
	Mat sumH = Mat::zeros(3, 3, CV_64F);
	int count = 0;
	for (int i = homoTransforms.size() - 400; i < homoTransforms.size(); i++) {
		sumH += homoTransforms[i];
		count++;
	}
	return sumH / count;
}

void readFrameFromCapture(VideoCapture* capture, Mat* frame)
{
	*capture >> *frame;

}

// Структура для хранения углов ориентации
struct OrientationAngles {
	double roll; // Крен (радианы)
	double pitch; // Тангаж (радианы)
	double yaw; // Рыскание (радианы)
};

// Функция для оценки ориентации по гомографии
OrientationAngles estimateOrientationFromHomography(const cv::Mat& H, double focalLength, double cx, double cy) {
	OrientationAngles angles;

	// Нормализация матрицы гомографии
	cv::Mat Hnorm = H / H.at<double>(2, 2);

	// Извлечение компонент вращения
	double h11 = Hnorm.at<double>(0, 0), h12 = Hnorm.at<double>(0, 1), h13 = Hnorm.at<double>(0, 2);
	double h21 = Hnorm.at<double>(1, 0), h22 = Hnorm.at<double>(1, 1), h23 = Hnorm.at<double>(1, 2);
	double h31 = Hnorm.at<double>(2, 0), h32 = Hnorm.at<double>(2, 1), h33 = Hnorm.at<double>(2, 2);

	// Вычисление углов
	angles.yaw = atan2(h21, h11);
	angles.pitch = atan2(-h31, sqrt(h32 * h32 + h33 * h33));
	angles.roll = atan2(h32, h33);

	return angles;
}

// Основная функция обработки
OrientationAngles estimateUAVOrientation(cv::cuda::GpuMat& currentFrame, cv::cuda::GpuMat& previousFrame,
	double focalLength, double cx, double cy) {
	// Преобразование в grayscale
	cv::cuda::GpuMat prevGray, currGray;
	cv::cuda::cvtColor(previousFrame, prevGray, cv::COLOR_BGR2GRAY);
	cv::cuda::cvtColor(currentFrame, currGray, cv::COLOR_BGR2GRAY);

	// Детекция особенностей (используем ORB на GPU)
	auto detector = cv::cuda::ORB::create(1000);

	// Для хранения ключевых точек и дескрипторов
	std::vector<cv::KeyPoint> prevKeypoints, currKeypoints;
	cv::cuda::GpuMat prevDescriptorsGPU, currDescriptorsGPU;

	// Детекция и вычисление дескрипторов
	detector->detectAndCompute(prevGray, cv::cuda::GpuMat(), prevKeypoints, prevDescriptorsGPU);
	detector->detectAndCompute(currGray, cv::cuda::GpuMat(), currKeypoints, currDescriptorsGPU);

	// Конвертируем дескрипторы в CPU формат
	cv::Mat prevDescriptors, currDescriptors;
	prevDescriptorsGPU.download(prevDescriptors);
	currDescriptorsGPU.download(currDescriptors);

	// Сопоставление особенностей
	auto matcher = cv::DescriptorMatcher::create("BruteForce-Hamming");
	std::vector<cv::DMatch> matches;
	matcher->match(prevDescriptors, currDescriptors, matches);

	// Фильтрация хороших соответствий
	double minDist = DBL_MAX;
	for (const auto& m : matches) {
		if (m.distance < minDist) minDist = m.distance;
	}

	std::vector<cv::DMatch> goodMatches;
	for (const auto& m : matches) {
		if (m.distance < std::max(2.0 * minDist, 30.0)) {
			goodMatches.push_back(m);
		}
	}

	// Получаем точки соответствий
	std::vector<cv::Point2f> prevPoints, currPoints;
	for (const auto& m : goodMatches) {
		prevPoints.push_back(prevKeypoints[m.queryIdx].pt);
		currPoints.push_back(currKeypoints[m.trainIdx].pt);
	}

	// Вычисляем гомографию
	cv::Mat H;
	if (prevPoints.size() >= 4) {
		H = cv::findHomography(prevPoints, currPoints, cv::RANSAC, 3.0);
	}
	else {
		// Недостаточно точек для оценки
		return OrientationAngles{ 0, 0, 0 };
	}

	// Оцениваем углы ориентации из гомографии
	return estimateOrientationFromHomography(H, focalLength, cx, cy);
}